#!/bin/bash
{{ ansible_managed | comment }}

{% set destination          = 'backups-from-' ~ inventory_hostname %}
{% set home_backup_file     = 'home-' ~ inventory_hostname %}
{% set www_backup_file      = 'www-' ~ inventory_hostname %}
{% set docker_backup_file   = 'docker-' ~ inventory_hostname %}
{% set mysql_backup_file    = 'all-databases-' ~ inventory_hostname %}
{% set mysql_users_file     = 'db_users-' ~ inventory_hostname %}

# We stream backups direct to s3 so we don't have to deal with massive
# backup files lying around on the server.

# Filesystem
nice tar -C / -cz var/www | \
  aws s3 cp - s3://gothick.org.uk-backup/{{ destination }}/{{ www_backup_file}}.tgz

# We're not using Docker at the moment, but if we were, we'd back it up like this:
# nice tar -C / -cz var/docker | \
#   aws s3 cp - s3://gothick.org.uk-backup/{{ destination }}/{{ docker_backup_file }}.tgz

nice tar -C / -cz home | \
  aws s3 cp - s3://gothick.org.uk-backup/{{ destination }}/{{ home_backup_file }}.tgz

# Databases

# All databases
# https://stackoverflow.com/a/58967178/300836 tells you why I'm ignoring a couple of system tables
nice mysqldump --all-databases --flush-privileges --ignore-table=mysql.innodb_table_stats \
  --ignore-table=mysql.innodb_index_stats | gzip -9 | \
  aws s3 cp - s3://gothick.org.uk-backup/{{ destination }}/{{ mysql_backup_file }}.sql.gz

# Individual databases, except for system databases
candidates=$(echo "show databases" | mysql | grep -Ev "^(Database|mysql|performance_schema|information_schema)$")
for candidate in $candidates; do
  nice mysqldump --flush-privileges --databases $candidate | gzip -9 | \
    aws s3 cp - s3://gothick.org.uk-backup/{{ destination }}/db-$candidate.sql.gz
done

# Users and privileges
pt-show-grants | gzip -9 | \
  aws s3 cp - s3://gothick.org.uk-backup/{{ destination }}/{{ mysql_users_file }}.sql.gz
